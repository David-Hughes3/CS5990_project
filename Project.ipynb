{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "FWCckN8D3Rgl",
        "Fo6JZ6cTD0Rh"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "nA_YTH0WFIDz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# CS5990 Project"
      ]
    },
    {
      "metadata": {
        "id": "YwAkFs68F6nf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        " This project covers how to use the [Tensorflow Object Detection API ](https://github.com/tensorflow/models/tree/master/research/object_detection) in google colaboratory. \n",
        "\n",
        "There are two sources for this code: \n",
        "\n",
        "*   [Training for the custom images source](https://github.com/EdjeElectronics/TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10/blob/master/README.md)\n",
        "*   object_detection_tutorial.ipynb in [Object Detection API repository](https://github.com/tensorflow/models/tree/master/research/object_detection)\n",
        "\n",
        "There are three sections to this code. First is building the object detection environment; these instructions can easily be found in the installation instructions in the API. Since the libraries are already installed in colab, it taks a lot of the difficulty out of the setup process. Second, we set up the training loop; this includes downloading the FasterRCNN pretrained model in order to leverage transfer learning. The code and data comes from the Edje tutorial for this section. Third, we run the object detector using code from object_detection_tutorial.ipynb. This allows us to make a prediction about there being a playing card of one of the six classes in the images.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "npT5UIrzKOyY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Directory Structure of uploaded files **\n",
        "\n",
        "\n",
        "/custom\n",
        "\n",
        "    -/images\n",
        "        -/test\n",
        "            -.JPG files of images\n",
        "            -.xml files of bounding boxes\n",
        "        -/train\n",
        "            -.JPG files of images\n",
        "            -.xml files of bounding boxes from imageLbl\n",
        "    -/testing\n",
        "        -.JPG files\n",
        "    -/training\n",
        "        -faster_rcnn_inception_v2_pets.config\n",
        "        -labelmap.pbtxt\n",
        "    -generate_tfrecord.py\n",
        "    -sizeChecker.py\n",
        "    -xml_to_csv.py\n",
        "    \n",
        "    \n",
        "**What should be modified**\n",
        "\n",
        "\n",
        "*   Add your own images and xml files from labelImg to custom/images/test/ and custom/images/train\n",
        "*   Add your own images to custom/testing\n",
        "*   Change faster_rcnn_inception_v2_pets.config and labelmap.pbtxt\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "ODJhNamJN-Cg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#command to remove all working files in colab\n",
        "#!rm -rf /content/*"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8BlDEku9NMZU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#IF YOU WANT TO UPLOAD YOUR OWN CUSTOM DATASET THEN COMMENT THIS CODE OUT, otherwise this contains all of the needed files to run this colab notebook\n",
        "!git clone https://github.com/David-Hughes3/CS5990_project.git\n",
        "!mv /content/CS5990_project/custom /content/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZFzGgc9JpcAT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# #uncomment this block if you want to upload your own custom folder (as a zip file)\n",
        "# !unzip custom.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HEWiY-MbFLtv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Set up Object Detection Environment"
      ]
    },
    {
      "metadata": {
        "id": "mJhcuUwuPgik",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Install the Prereqs for the Object Detection API and test using the model builder test**"
      ]
    },
    {
      "metadata": {
        "id": "uawRUy6SOjEv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#library dependencies\n",
        "!apt-get install protobuf-compiler python-pil python-lxml python-tk"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wlo0mRRIOy50",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#clone the tensorflow models API that contains the /content/models/research/object_detection folder\n",
        "!git clone https://github.com/tensorflow/models.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZSb6Zb7nQjEe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#COCO API installation\n",
        "#pretrained models\n",
        "!git clone https://github.com/cocodataset/cocoapi.git\n",
        "!cd cocoapi/PythonAPI && make && cp -r pycocotools /content/models/research/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zvR7OUigPJUH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd /content/models/research"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-VWb67XxPYOM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Add Libraries to PYTHONPATH\n",
        "#Add Libraries to PYTHONPATH\n",
        "import os\n",
        "os.environ['PYTHONPATH'] += \":/content/models/research\"\n",
        "os.environ['PYTHONPATH'] += \":/content/models/research/slim\"\n",
        "os.environ['PYTHONPATH'] += \":/content/models/research/object_detection\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NvwmoEsmdq7x",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!echo $PYTHONPATH"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GLgV9nFqPZ8q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#\"Tensorflow Object Detection API uses Protobufs to configure model and training parameters\"\n",
        "#\"Before the framework can be used, the Protobuf libraries must be compiled\" in \"tensorflow/models/research/ directory\"\n",
        "!protoc object_detection/protos/*.proto --python_out=."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yT1FiHZBPboR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#\" test that you have correctly installed the Tensorflow Object Detection API by running the following command\"\n",
        "!python object_detection/builders/model_builder_test.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "svAXlI99ItKq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Set up for the Training process"
      ]
    },
    {
      "metadata": {
        "id": "jl86UTB9Uly_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Get Pretrained model**\n",
        "\n",
        "We download a pretrained model to use transfer learning from Tensorflows model zoo."
      ]
    },
    {
      "metadata": {
        "id": "3HPZBc4bU627",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd object_detection"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "J0eNjDBDUkud",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#download the FasterRCNN pretrained model from tensorflow's model zoo\n",
        "!wget http://download.tensorflow.org/models/object_detection/faster_rcnn_inception_v2_coco_2018_01_28.tar.gz\n",
        "!tar -xvf faster_rcnn_inception_v2_coco_2018_01_28.tar.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dDOfvNKrJ8ZA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Get tutorial code and data**\n",
        "\n",
        "MAKE SURE TO FOLLOW THE DIRECTORY STRUCTURE IF YOU USED CUSTOM DATA\n",
        "\n",
        "By default this data and scripts come from the Edje Electronics tutorial. It has been changed into a specific structure to make it straightforward to move the files into the Object Detection API directory structure."
      ]
    },
    {
      "metadata": {
        "id": "8C1M2l34J7rK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#copy data to /object_detection\n",
        "!mkdir /content/models/research/object_detection/images\n",
        "!cp -r /content/custom/images/test /content/models/research/object_detection/images\n",
        "!cp -r /content/custom/images/train /content/models/research/object_detection/images \n",
        "\n",
        "!cp -r /content/custom/testing /content/models/research/object_detection\n",
        "\n",
        "#copy python scripts to object_detection\n",
        "!cp /content/custom/generate_tfrecord.py /content/models/research/object_detection/\n",
        "!cp /content/custom/sizeChecker.py /content/models/research/object_detection/\n",
        "!cp /content/custom/xml_to_csv.py /content/models/research/object_detection/\n",
        "\n",
        "#move the modified pipeline config file and the label map file\n",
        "!cp -r /content/custom/training /content/models/research/object_detection\n",
        "\n",
        "#move the modified model_main.py\n",
        "!cp /content/custom/model_main.py /content/models/research/object_detection/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rwNZAkwnEN4N",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#check if the drawn xml bounding boxes are OK\n",
        "!python sizeChecker.py --move"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UTYsXI4COvuq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**XML -> CSV -> tfrecord**\n",
        "\n",
        "Using LabelImg we made XML files that contain bounding box labels for each object in the image.  We turn these labels into a CSV file using a python script. \n",
        "\n",
        "Tensorflow records are TF's own binary storage format. We use another script to convert the CSV of labels and the images into .record files."
      ]
    },
    {
      "metadata": {
        "id": "JEKXDXv5OvM9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#create images XML files -> CSV\n",
        "!python xml_to_csv.py\n",
        "#generate tensorflow record files\n",
        "!python generate_tfrecord.py --csv_input=images/train_labels.csv --image_dir=images/train --output_path=train.record\n",
        "!python generate_tfrecord.py --csv_input=images/test_labels.csv --image_dir=images/test --output_path=test.record"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "spgoojEhsaWb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Run Training**\n",
        "\n",
        "In order to monitor the training, we first setup tensorboard in colab. There are occasional issues with using tensorboard with colab, so be aware.\n",
        "\n",
        "To use tensorboard, simply click the link in the std output.\n",
        "\n",
        "\n",
        "Next we run the command that starts the actual training process of the model. We output the output into a log file as it is too large. We output checkpoints into the training directory. The default steps are setup in the config file.\n",
        "\n",
        "NOTE: you can stop the training early and simply continue by using Run After in the next cell.\n"
      ]
    },
    {
      "metadata": {
        "id": "OUWMs9aatDui",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#to open tensorboard open the link in the output\n",
        "#NOTE: there are problems with the package and tensorboard at times\n",
        "import os\n",
        "LOG_DIR = '/content/models/research/object_detection/training'\n",
        "\n",
        "if os.path.isfile('/content/ngrok-stable-linux-amd64.zip'):\n",
        "  print('already downloaded zip file')\n",
        "else:\n",
        "  !wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip -P /content/\n",
        "  !unzip /content/ngrok-stable-linux-amd64.zip\n",
        "\n",
        "\n",
        "if not os.path.exists(LOG_DIR):\n",
        "  os.makedirs(LOG_DIR)\n",
        "  \n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR))\n",
        "\n",
        "get_ipython().system_raw('./ngrok http 6006 &')\n",
        "\n",
        "!curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JKwTmRXvsiKM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#command that runs the training\n",
        "!python /content/models/research/object_detection/model_main.py \\\n",
        "    --pipeline_config_path=/content/models/research/object_detection/training/faster_rcnn_inception_v2_pets.config \\\n",
        "    --model_dir=/content/models/research/object_detection/training/ \\\n",
        "    --num_train_steps=10000 \\\n",
        "    --sample_1_of_n_eval_examples=1 \\\n",
        "    --alsologtostderr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t0GvVMK9G2iD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# #display some random lines in the file\n",
        "# fp = open(\"/content/training_log.txt\")\n",
        "# for i, line in enumerate(fp):\n",
        "#   if i % 100 == 0:\n",
        "#     print(line)\n",
        "# fp.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hNbFe3hGuqtO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Export the Inference Graph**\n",
        "\n",
        "To save and later restore the trained graph, we output the inference graph using a built in script in the object detection api"
      ]
    },
    {
      "metadata": {
        "id": "eUf9VHznd6Px",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!cd /content/models/research/object_detection\n",
        "!rm -r inference_graph"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HXDbLXreutOS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "ckpts = [ i  for i in glob.glob(\"/content/models/research/object_detection/training/*\") if '.ckpt' in i]\n",
        "print(ckpts)\n",
        "XXXX = 0\n",
        "for f in ckpts:\n",
        "  temp = (f.split('.ckpt-'))[1].split('.')[0]\n",
        "  if int(temp) > XXXX:\n",
        "    XXXX = int(temp) \n",
        "\n",
        "os.environ[\"TRAINING_CHECKPOINT_PREFIX\"] = str(\"training/model.ckpt-\" + str(XXXX))\n",
        "    \n",
        "!python export_inference_graph.py --input_type image_tensor --pipeline_config_path training/faster_rcnn_inception_v2_pets.config --trained_checkpoint_prefix $TRAINING_CHECKPOINT_PREFIX --output_directory inference_graph"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FWCckN8D3Rgl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Run Object Detector\n",
        "\n",
        "This code comes from the object detection api's tutorial jupyter notebook."
      ]
    },
    {
      "metadata": {
        "id": "h-XCcwEO5OKc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import six.moves.urllib as urllib\n",
        "import sys\n",
        "import tarfile\n",
        "import tensorflow as tf\n",
        "import zipfile\n",
        "\n",
        "from distutils.version import StrictVersion\n",
        "from collections import defaultdict\n",
        "from io import StringIO\n",
        "# This is needed to display the images.\n",
        "%matplotlib inline \n",
        "%matplotlib inline\n",
        "import matplotlib\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "from PIL import Image\n",
        "\n",
        "# This is needed since the notebook is stored in the object_detection folder.\n",
        "sys.path.append(\"..\")\n",
        "from object_detection.utils import ops as utils_ops\n",
        "\n",
        "if StrictVersion(tf.__version__) < StrictVersion('1.12.0'):\n",
        "  raise ImportError('Please upgrade your TensorFlow installation to v1.12.*.')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mDCoEKkl7uNR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#object detection tools\n",
        "from utils import label_map_util\n",
        "from utils import visualization_utils as vis_util"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ybCUznpy3Xll",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Path to frozen detection graph. This is the actual model that is used for the object detection.\n",
        "PATH_TO_FROZEN_GRAPH = os.path.join('inference_graph','frozen_inference_graph.pb')\n",
        "\n",
        "# List of the strings that is used to add correct label for each box.\n",
        "PATH_TO_LABELS = os.path.join('training', 'labelmap.pbtxt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OzL0P0Ok4qAU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Load frozen graph into memory**"
      ]
    },
    {
      "metadata": {
        "id": "gKKtH_rK4tML",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "detection_graph = tf.Graph()\n",
        "with detection_graph.as_default():\n",
        "  od_graph_def = tf.GraphDef()\n",
        "  with tf.gfile.GFile(PATH_TO_FROZEN_GRAPH, 'rb') as fid:\n",
        "    serialized_graph = fid.read()\n",
        "    od_graph_def.ParseFromString(serialized_graph)\n",
        "    tf.import_graph_def(od_graph_def, name='')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JHmgh3P24xQ6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Load label maps**"
      ]
    },
    {
      "metadata": {
        "id": "iedjMiVd4zOC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XGebZhbB42Eq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Helper code**"
      ]
    },
    {
      "metadata": {
        "id": "D73DCTMn41ry",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_image_into_numpy_array(image):\n",
        "  (im_width, im_height) = image.size\n",
        "  return np.array(image.getdata()).reshape(\n",
        "      (im_height, im_width, 3)).astype(np.uint8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JAZetJLD45P7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Detection**"
      ]
    },
    {
      "metadata": {
        "id": "4n2bgc7b46HJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir /content/models/research/object_detection/testing/output\n",
        "# For the sake of simplicity we will use only 2 images:\n",
        "# image1.jpg\n",
        "# image2.jpg\n",
        "# If you want to test the code with your images, just add path to the images to the TEST_IMAGE_PATHS.\n",
        "PATH_TO_TEST_IMAGES_DIR = '/content/models/research/object_detection/testing'\n",
        "#TEST_IMAGE_PATHS = [ os.path.join(PATH_TO_TEST_IMAGES_DIR, 'image{}.JPG'.format(i)) for i in range(1, 3) ]\n",
        "TEST_IMAGE_PATHS = ['/content/models/research/object_detection/testing/test1.JPG']\n",
        "\n",
        "# Size, in inches, of the output images.\n",
        "IMAGE_SIZE = (5, 3) #(W,H)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4Q3apSdC5BmQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def run_inference_for_single_image(image, graph):\n",
        "  with graph.as_default():\n",
        "    with tf.Session() as sess:\n",
        "      # Get handles to input and output tensors\n",
        "      ops = tf.get_default_graph().get_operations()\n",
        "      all_tensor_names = {output.name for op in ops for output in op.outputs}\n",
        "      tensor_dict = {}\n",
        "      for key in [\n",
        "          'num_detections', 'detection_boxes', 'detection_scores',\n",
        "          'detection_classes', 'detection_masks'\n",
        "      ]:\n",
        "        tensor_name = key + ':0'\n",
        "        if tensor_name in all_tensor_names:\n",
        "          tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\n",
        "              tensor_name)\n",
        "      if 'detection_masks' in tensor_dict:\n",
        "        # The following processing is only for single image\n",
        "        detection_boxes = tf.squeeze(tensor_dict['detection_boxes'], [0])\n",
        "        detection_masks = tf.squeeze(tensor_dict['detection_masks'], [0])\n",
        "        # Reframe is required to translate mask from box coordinates to image coordinates and fit the image size.\n",
        "        real_num_detection = tf.cast(tensor_dict['num_detections'][0], tf.int32)\n",
        "        detection_boxes = tf.slice(detection_boxes, [0, 0], [real_num_detection, -1])\n",
        "        detection_masks = tf.slice(detection_masks, [0, 0, 0], [real_num_detection, -1, -1])\n",
        "        detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
        "            detection_masks, detection_boxes, image.shape[0], image.shape[1])\n",
        "        detection_masks_reframed = tf.cast(\n",
        "            tf.greater(detection_masks_reframed, 0.5), tf.uint8)\n",
        "        # Follow the convention by adding back the batch dimension\n",
        "        tensor_dict['detection_masks'] = tf.expand_dims(\n",
        "            detection_masks_reframed, 0)\n",
        "      image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')\n",
        "\n",
        "      # Run inference\n",
        "      output_dict = sess.run(tensor_dict,\n",
        "                             feed_dict={image_tensor: np.expand_dims(image, 0)})\n",
        "\n",
        "      # all outputs are float32 numpy arrays, so convert types as appropriate\n",
        "      output_dict['num_detections'] = int(output_dict['num_detections'][0])\n",
        "      output_dict['detection_classes'] = output_dict[\n",
        "          'detection_classes'][0].astype(np.uint8)\n",
        "      output_dict['detection_boxes'] = output_dict['detection_boxes'][0]\n",
        "      output_dict['detection_scores'] = output_dict['detection_scores'][0]\n",
        "      if 'detection_masks' in output_dict:\n",
        "        output_dict['detection_masks'] = output_dict['detection_masks'][0]\n",
        "  return output_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K3SgrCly5HML",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "for image_path in TEST_IMAGE_PATHS:\n",
        "  image = Image.open(image_path)\n",
        "  # the array based representation of the image will be used later in order to prepare the\n",
        "  # result image with boxes and labels on it.\n",
        "  image_np = load_image_into_numpy_array(image)\n",
        "  # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
        "  image_np_expanded = np.expand_dims(image_np, axis=0)\n",
        "  # Actual detection.\n",
        "  output_dict = run_inference_for_single_image(image_np, detection_graph)\n",
        "  # Visualization of the results of a detection.\n",
        "  vis_util.visualize_boxes_and_labels_on_image_array(\n",
        "      image_np,\n",
        "      output_dict['detection_boxes'],\n",
        "      output_dict['detection_classes'],\n",
        "      output_dict['detection_scores'],\n",
        "      category_index,\n",
        "      instance_masks=output_dict.get('detection_masks'),\n",
        "      use_normalized_coordinates=True,\n",
        "      line_thickness=8,\n",
        "      min_score_thresh=0.70)\n",
        "  matplotlib.rcParams['figure.dpi']= 300 #raises the resolution of the test images with printed labels/boxes that are stored in object_detection/testing/output\n",
        "  plt.figure(figsize=IMAGE_SIZE)\n",
        "  plt.imshow(image_np)\n",
        "  plt.savefig('/content/models/research/object_detection/testing/output/' + (os.path.splitext(os.path.basename(image_path))[0]) + '.png' , dpi=300 )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Fo6JZ6cTD0Rh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Archive"
      ]
    },
    {
      "metadata": {
        "id": "cK3c9vjGrzcW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Move the legacy version 'train.py' into the object detection folder**\n",
        "\n",
        "train.py was combined with another file in the current version, we simply use the legacy version to train"
      ]
    },
    {
      "metadata": {
        "id": "7xIeUQiYrzFE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#!cp /content/models/research/object_detection/legacy/train.py /content/models/research/object_detection/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ejZerf9HD2Ei",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#default is step to 10000 steps\n",
        "#You can stop the training at any time and simply use Menu Bar > Runtime > Run After to stop the training early\n",
        "#output steps to a log file, because the amount of text crashes the colab notebook\n",
        "#!python train.py --logtostderr --train_dir=training/ --pipeline_config_path=training/faster_rcnn_inception_v2_pets.config 2> /content/training_log.txt"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}